{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6.6 模型集成提升性能</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "#定义一些超参数 \n",
    "BATCHSIZE=100\n",
    "DOWNLOAD_MNIST=False\n",
    "EPOCHES=20\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义相关模型结构，这三个网络结构比较接近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=16,kernel_size=5,stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=36,kernel_size=3,stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(1296,128)\n",
    "        self.fc2 = nn.Linear(128,10)      \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool1(F.relu(self.conv1(x)))\n",
    "        x=self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x=x.view(-1,36*6*6)\n",
    "        x=F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 36, 5)\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.aap=nn.AdaptiveAvgPool2d(1)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(36, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        # x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.aap(x)\n",
    "        # print(x.shape)\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # print(x.shape)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入数据，这里数据已下载本地，故设download=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net1 = CNNNet()\n",
    "net2 = Net()\n",
    "net3 = LeNet()\n",
    "net4 = VGG('VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0集成模型的正确率47.11\n",
      "模型0的正确率为：40.2\n",
      "模型1的正确率为：44.51\n",
      "模型2的正确率为：47.1\n",
      "epoch:1集成模型的正确率51.92\n",
      "模型0的正确率为：44.31\n",
      "模型1的正确率为：47.83\n",
      "模型2的正确率为：53.35\n",
      "epoch:2集成模型的正确率54.85\n",
      "模型0的正确率为：43.98\n",
      "模型1的正确率为：50.63\n",
      "模型2的正确率为：56.96\n",
      "epoch:3集成模型的正确率57.13\n",
      "模型0的正确率为：45.28\n",
      "模型1的正确率为：54.38\n",
      "模型2的正确率为：58.02\n",
      "epoch:4集成模型的正确率58.74\n",
      "模型0的正确率为：46.93\n",
      "模型1的正确率为：54.6\n",
      "模型2的正确率为：59.72\n",
      "epoch:5集成模型的正确率61.2\n",
      "模型0的正确率为：47.63\n",
      "模型1的正确率为：57.08\n",
      "模型2的正确率为：62.47\n",
      "epoch:6集成模型的正确率63.05\n",
      "模型0的正确率为：49.97\n",
      "模型1的正确率为：56.68\n",
      "模型2的正确率为：63.1\n",
      "epoch:7集成模型的正确率61.08\n",
      "模型0的正确率为：51.85\n",
      "模型1的正确率为：57.49\n",
      "模型2的正确率为：60.53\n",
      "epoch:8集成模型的正确率64.09\n",
      "模型0的正确率为：52.58\n",
      "模型1的正确率为：58.37\n",
      "模型2的正确率为：62.9\n",
      "epoch:9集成模型的正确率65.67\n",
      "模型0的正确率为：53.64\n",
      "模型1的正确率为：59.12\n",
      "模型2的正确率为：63.25\n",
      "epoch:10集成模型的正确率64.64\n",
      "模型0的正确率为：53.76\n",
      "模型1的正确率为：59.64\n",
      "模型2的正确率为：64.14\n",
      "epoch:11集成模型的正确率65.04\n",
      "模型0的正确率为：53.4\n",
      "模型1的正确率为：59.11\n",
      "模型2的正确率为：64.89\n",
      "epoch:12集成模型的正确率67.18\n",
      "模型0的正确率为：54.63\n",
      "模型1的正确率为：60.0\n",
      "模型2的正确率为：63.78\n",
      "epoch:13集成模型的正确率66.96\n",
      "模型0的正确率为：54.05\n",
      "模型1的正确率为：62.77\n",
      "模型2的正确率为：64.58\n",
      "epoch:14集成模型的正确率66.96\n",
      "模型0的正确率为：55.06\n",
      "模型1的正确率为：62.89\n",
      "模型2的正确率为：65.33\n",
      "epoch:15集成模型的正确率67.62\n",
      "模型0的正确率为：55.3\n",
      "模型1的正确率为：63.92\n",
      "模型2的正确率为：66.15\n",
      "epoch:16集成模型的正确率67.95\n",
      "模型0的正确率为：55.02\n",
      "模型1的正确率为：62.69\n",
      "模型2的正确率为：66.37\n",
      "epoch:17集成模型的正确率68.14\n",
      "模型0的正确率为：56.02\n",
      "模型1的正确率为：64.72\n",
      "模型2的正确率为：65.65\n",
      "epoch:18集成模型的正确率68.87\n",
      "模型0的正确率为：55.37\n",
      "模型1的正确率为：64.88\n",
      "模型2的正确率为：66.53\n",
      "epoch:19集成模型的正确率67.99\n",
      "模型0的正确率为：55.19\n",
      "模型1的正确率为：63.31\n",
      "模型2的正确率为：66.29\n"
     ]
    }
   ],
   "source": [
    "# 把3个网络模型放在一个列表里\n",
    "mlps=[net1.to(device),net2.to(device),net3.to(device)]\n",
    "\n",
    "optimizer=torch.optim.Adam([{\"params\":mlp.parameters()} for mlp in mlps],lr=LR)\n",
    "  \n",
    "loss_function=nn.CrossEntropyLoss()\n",
    " \n",
    "for ep in range(EPOCHES):\n",
    "    for img,label in trainloader:\n",
    "        img,label=img.to(device),label.to(device)\n",
    "        optimizer.zero_grad() # 10个网络清除梯度\n",
    "        for mlp in mlps:\n",
    "            mlp.train()\n",
    "            out=mlp(img)\n",
    "            loss=loss_function(out,label)\n",
    "            loss.backward() # 网络们获得梯度\n",
    "        optimizer.step()\n",
    " \n",
    "    pre=[]\n",
    "    vote_correct=0\n",
    "    mlps_correct=[0 for i in range(len(mlps))]\n",
    "    for img,label in testloader:\n",
    "        img,label=img.to(device),label.to(device)\n",
    "        for i, mlp in enumerate(mlps):\n",
    "            mlp.eval()\n",
    "            out=mlp(img)\n",
    " \n",
    "            _,prediction=torch.max(out,1) # 按行取最大值\n",
    "            pre_num=prediction.cpu().numpy()\n",
    "            mlps_correct[i]+=(pre_num==label.cpu().numpy()).sum()\n",
    " \n",
    "            pre.append(pre_num)\n",
    "        arr=np.array(pre)\n",
    "        pre.clear()\n",
    "        result=[Counter(arr[:,i]).most_common(1)[0][0] for i in range(BATCHSIZE)]\n",
    "        vote_correct+=(result == label.cpu().numpy()).sum()\n",
    "    print(\"epoch:\" + str(ep)+\"集成模型的正确率\"+str(vote_correct/len(testloader)))\n",
    " \n",
    "    for idx, coreect in enumerate(mlps_correct):\n",
    "        print(\"模型\"+str(idx)+\"的正确率为：\"+str(coreect/len(testloader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6.7 使用现代经典模型提升性能</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 2.00 GiB total capacity; 611.70 MiB already allocated; 11.71 MiB free; 688.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-22-9d03497afc13>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmlp\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmlps\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m             \u001B[0mmlp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m             \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmlp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m             \u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mloss_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m             \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# 网络们获得梯度\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\TF_2C\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-16-3613698e3af8>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\TF_2C\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\TF_2C\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 117\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    118\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\TF_2C\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\TF_2C\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    134\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrunning_mean\u001B[0m \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrack_running_stats\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    135\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrunning_var\u001B[0m \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrack_running_stats\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 136\u001B[1;33m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001B[0m\u001B[0;32m    137\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\anaconda3\\envs\\TF_2C\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mbatch_norm\u001B[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[0;32m   2056\u001B[0m     return torch.batch_norm(\n\u001B[0;32m   2057\u001B[0m         \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrunning_mean\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrunning_var\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2058\u001B[1;33m         \u001B[0mtraining\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmomentum\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meps\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackends\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcudnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menabled\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2059\u001B[0m     )\n\u001B[0;32m   2060\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 2.00 GiB total capacity; 611.70 MiB already allocated; 11.71 MiB free; 688.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "mlps=[net4.to(device)]\n",
    "\n",
    "optimizer=torch.optim.Adam([{\"params\":mlp.parameters()} for mlp in mlps],lr=LR)\n",
    "  \n",
    "loss_function=nn.CrossEntropyLoss()\n",
    " \n",
    "for ep in range(EPOCHES):\n",
    "    for img,label in trainloader:\n",
    "        img,label=img.to(device),label.to(device)\n",
    "        optimizer.zero_grad() # 10个网络清除梯度\n",
    "        for mlp in mlps:\n",
    "            mlp.train()\n",
    "            out=mlp(img)\n",
    "            loss=loss_function(out,label)\n",
    "            loss.backward() # 网络们获得梯度\n",
    "        # 对所有的参数进行更新\n",
    "        optimizer.step()\n",
    " \n",
    "    pre=[]\n",
    "    vote_correct=0\n",
    "    mlps_correct=[0 for i in range(len(mlps))]\n",
    "    for img,label in testloader:\n",
    "        img,label=img.to(device),label.to(device)\n",
    "        for i, mlp in enumerate(mlps):\n",
    "            mlp.eval()\n",
    "            out=mlp(img)\n",
    " \n",
    "            _,prediction=torch.max(out,1) # 按行取最大值\n",
    "            pre_num=prediction.cpu().numpy()\n",
    "            mlps_correct[i]+=(pre_num==label.cpu().numpy()).sum()\n",
    " \n",
    "            pre.append(pre_num)\n",
    "        arr=np.array(pre)\n",
    "        pre.clear()\n",
    "        result=[Counter(arr[:,i]).most_common(1)[0][0] for i in range(BATCHSIZE)]\n",
    "        vote_correct+=(result == label.cpu().numpy()).sum()\n",
    "    # print(\"epoch:\" + str(ep)+\"集成模型的正确率\"+str(vote_correct/len(testloader)))\n",
    " \n",
    "    for idx, coreect in enumerate(mlps_correct):\n",
    "        print(\"VGG16模型迭代\"+str(ep)+\"次的正确率为：\"+str(coreect/len(testloader)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}